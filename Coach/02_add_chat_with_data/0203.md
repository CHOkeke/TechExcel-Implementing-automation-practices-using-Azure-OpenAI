# Task 03 - Add custom chat to a Streamlit dashboard (30 minutes)

- Be sure that all Python packages are installed before trying to run Streamlit. At the command line and inside the `src\ContosoSuitesDashboard\` folder, execute the following command: `pip install -r requirements.txt`
- Modify the `config.json` file to fill in values for each of the configuration settings. For **AOAIEndpoint** and **SearchEndpoint**, you will want to include this as a URL, starting with `https://`.
- The `main()` function calls a `chat_with_data()` function. This function's intent is to do three things: initialize chat history, display chat messages from history, and handle user messages.
  - The code for the completed `chat_with_data()` function is as follows:

    ```python
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display chat messages from history on app rerun
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Await a user message and handle the chat prompt when it comes in.
    if prompt := st.chat_input("Enter a message:"):
        handle_chat_prompt(prompt)
    ```

- The `handle_chat_prompt()` function does two things: it echoes the user's prompt to the chat window, and then it sends the prompt to Azure OpenAI and writes the resulting message to the chat window.
  - The code for the completed `handle_chat_prompt()` function is as follows:

    ```python
    # Echo the user's prompt to the chat window
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Send the user's prompt to Azure OpenAI and display the response
    # The call to Azure OpenAI is handled in create_chat_completion()
    # This function loops through the responses and displays them as they come in.
    # It also appends the full response to the chat history.
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for response in create_chat_completion(deployment_name, st.session_state.messages, config["SearchEndpoint"], config["SearchKey"], config["SearchIndex"]):
            full_response += (response.choices[0].delta.content or "")
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    ```

- The `create_chat_completion()` function reaches out to Azure OpenAI and performs the chat completion, ensuring that we only include information from our Azure AI Search index.
  - The code for the completed `create_chat_completion()` function is as follows:

    ```python
    # Create and return a new chat completion request
    # Be sure to include the "extra_body" parameter to use Azure AI Search as the data source
    return client.chat.completions.create(
        model=deployment_name,
        messages=[
            {"role": m["role"], "content": m["content"]}
            for m in messages
        ],
        stream=True,
        extra_body={
            "dataSources": [
                {
                    "type": "AzureCognitiveSearch",
                    "parameters": {
                        "endpoint": endpoint,
                        "key": key,
                        "indexName": index_name,
                    }
                }
            ]
        }
    )
    ```
